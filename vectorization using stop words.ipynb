{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71693294-c939-459b-b587-06be882ca454",
   "metadata": {},
   "source": [
    "### vectorization technique: Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae1ebeff-9167-4b35-ab1d-cd9eae20d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b6d6df6-5614-40f7-ac13-692e1ada84c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Mohd Ashjaa\n",
      "[nltk_data]     Khan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fb0c2c1-5e8b-4d14-9322-252568f01e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Mohd Ashjaa\n",
      "[nltk_data]     Khan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75bebe3c-28a9-41c7-8abc-ad209a4a5b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Mohd Ashjaa\n",
      "[nltk_data]     Khan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b94c9c6-f470-4dd5-b221-6f4d34327fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "665d31b6-3dbe-4be1-8197-95d91c0457ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67cb2318-11b6-47ac-a395-aecb5807ebbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus: This is simple example of vectorization using stop words.\n"
     ]
    }
   ],
   "source": [
    "corpus=\"\"\"This is simple example of vectorization using stop words.\"\"\"\n",
    "print(\"corpus:\",corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b60c40fb-e311-4115-bf3c-53531c2d8702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words tokenize: ['This', 'is', 'simple', 'example', 'of', 'vectorization', 'using', 'stop', 'words', '.']\n"
     ]
    }
   ],
   "source": [
    "words=word_tokenize(corpus)\n",
    "print(\"words tokenize:\",words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f321fd3d-a939-4d81-9b46-1408b2fb9a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
     ]
    }
   ],
   "source": [
    "eng_stword=stopwords.words(\"english\")\n",
    "print(eng_stword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a77df95e-a14f-42c4-8b1d-d3abcbe5dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words=[]\n",
    "for word in words:\n",
    "    word=word.lower()\n",
    "    if word in eng_stword:\n",
    "        pass\n",
    "    else:\n",
    "        filtered_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31ae198e-839c-4d91-9ef9-42eb73b666de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered words without stop words: ['simple', 'example', 'vectorization', 'using', 'stop', 'words', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"filtered words without stop words:\",filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1724b70c-4cbd-4359-8229-0da8686af4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length before removing stop words: 57\n",
      "length afte removing stop words: 7\n"
     ]
    }
   ],
   "source": [
    "print(\"length before removing stop words:\",len(corpus))\n",
    "print(\"length afte removing stop words:\",len(filtered_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9482bb2d-c6b7-49e3-9cbb-3a36b8196ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
